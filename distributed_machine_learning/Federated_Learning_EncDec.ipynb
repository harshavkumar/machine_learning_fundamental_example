{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Manual Client-Server Simulation: ** \\\\\n",
        "\n",
        "Instead of using tensorflow_federated, the code now simulates federated learning manually.  \\\\\n",
        "Each client trains its model on decrypted data (simulating how the encrypted data would be processed if decryption happened during training).\n",
        "After each round, the server aggregates the weights by averaging the client model weights.  \\\\\n",
        "\n",
        "**Print Dataset:** \\\\\n",
        "\n",
        "The plain dataset is printed first. The encrypted dataset is printed to demonstrate the Paillier encryption process. \\\\\n",
        "\n",
        "**Training Process:** \\\\\n",
        "\n",
        "\n",
        "\n",
        "Each client trains its model on its own (decrypted) data, and the server aggregates the weights after each round.  \\\\\n",
        "\n",
        "The code prints the loss and accuracy for each client after training.\n",
        "Metrics: \\\\\n",
        "\n",
        "At the end of each round, we print out the loss and accuracy metrics for each client model. \\\\"
      ],
      "metadata": {
        "id": "IVjp_odksTTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from phe import paillier\n",
        "\n",
        "# Step 1: Paillier Encryption Key Generation\n",
        "public_key, private_key = paillier.generate_paillier_keypair()\n",
        "\n",
        "# Step 2: Dataset Creation (Encrypted)\n",
        "def create_dataset():\n",
        "    \"\"\"\n",
        "    Generate a dataset with random values for features and binary labels.\n",
        "    Returns:\n",
        "        x_data (ndarray): Feature data of shape (10, 2)\n",
        "        y_data (ndarray): Binary labels of shape (10, 1)\n",
        "    \"\"\"\n",
        "    x_data = np.random.rand(10, 2)  # 10 samples with 2 features\n",
        "    y_data = np.random.randint(0, 2, size=(10, 1))  # Binary labels reshaped to (10, 1)\n",
        "    return x_data, y_data\n",
        "\n",
        "# Step 3: Encrypt Dataset\n",
        "def encrypt_dataset(x_data, y_data, public_key):\n",
        "    \"\"\"\n",
        "    Encrypts the dataset using the Paillier public key.\n",
        "    Args:\n",
        "        x_data (ndarray): Feature data\n",
        "        y_data (ndarray): Label data\n",
        "        public_key (PaillierPublicKey): Public key for encryption\n",
        "    Returns:\n",
        "        encrypted_x (list): Encrypted feature data\n",
        "        encrypted_y (list): Encrypted label data\n",
        "    \"\"\"\n",
        "    encrypted_x = [[public_key.encrypt(value) for value in row] for row in x_data]\n",
        "    encrypted_y = [public_key.encrypt(int(label)) for label in y_data.flatten()]\n",
        "    return encrypted_x, encrypted_y\n",
        "\n",
        "# Step 4: Simulate Encrypted Operations\n",
        "def encrypted_addition(enc_val1, enc_val2):\n",
        "    \"\"\"\n",
        "    Perform encrypted addition using Paillier.\n",
        "    Args:\n",
        "        enc_val1 (EncryptedNumber): Encrypted value 1\n",
        "        enc_val2 (EncryptedNumber): Encrypted value 2\n",
        "    Returns:\n",
        "        EncryptedNumber: Result of addition\n",
        "    \"\"\"\n",
        "    return enc_val1 + enc_val2\n",
        "\n",
        "def encrypted_multiply_constant(enc_val, constant):\n",
        "    \"\"\"\n",
        "    Perform encrypted multiplication with a constant using Paillier.\n",
        "    Args:\n",
        "        enc_val (EncryptedNumber): Encrypted value\n",
        "        constant (float): Constant to multiply\n",
        "    Returns:\n",
        "        EncryptedNumber: Result of multiplication\n",
        "    \"\"\"\n",
        "    return enc_val * constant\n",
        "\n",
        "# Step 5: Simulate a Dense Layer Forward Pass\n",
        "def dense_layer_forward(enc_x_row, weights, bias, public_key):\n",
        "    \"\"\"\n",
        "    Simulates a forward pass through a dense layer using encrypted inputs.\n",
        "    Args:\n",
        "        enc_x_row (list): Encrypted input features for one sample\n",
        "        weights (list): Plaintext weights for the dense layer\n",
        "        bias (float): Plaintext bias for the dense layer\n",
        "        public_key (PaillierPublicKey): Public key for encryption\n",
        "    Returns:\n",
        "        EncryptedNumber: Encrypted output from the dense layer\n",
        "    \"\"\"\n",
        "    # Simulate weighted sum (dot product) between encrypted inputs and weights\n",
        "    weighted_sum = encrypted_addition(\n",
        "        encrypted_multiply_constant(enc_x_row[0], weights[0]),\n",
        "        encrypted_multiply_constant(enc_x_row[1], weights[1])\n",
        "    )\n",
        "\n",
        "    # Add bias (bias is plaintext, so we encrypt it)\n",
        "    encrypted_bias = public_key.encrypt(bias)\n",
        "    output = encrypted_addition(weighted_sum, encrypted_bias)\n",
        "\n",
        "    # Apply a simple activation function approximation (like sigmoid or ReLU)\n",
        "    # For this simulation, we'll just use multiplication by a constant as a simple approximation\n",
        "    activated_output = encrypted_multiply_constant(output, 0.1)  # Simulate sigmoid approximation\n",
        "\n",
        "    return activated_output\n",
        "\n",
        "# Step 6: Train on Encrypted Data\n",
        "def train_on_encrypted_data(encrypted_x, encrypted_y, public_key):\n",
        "    \"\"\"\n",
        "    Simulates training on encrypted data. Since Paillier does not support\n",
        "    certain operations like multiplying two encrypted numbers, this function\n",
        "    uses conceptual approximations.\n",
        "    Args:\n",
        "        encrypted_x (list): Encrypted feature data\n",
        "        encrypted_y (list): Encrypted label data\n",
        "        public_key (PaillierPublicKey): Public key for encryption\n",
        "    \"\"\"\n",
        "    # Define weights and bias for the dense layer (these are plaintext constants)\n",
        "    weights = [0.5, 0.5]  # Two weights corresponding to two input features\n",
        "    bias = 0.1  # Bias for the dense layer\n",
        "\n",
        "    for epoch in range(10):  # Simulate 10 epochs\n",
        "        print(f\"\\n--- Epoch {epoch + 1} ---\")\n",
        "\n",
        "        total_encrypted_loss = public_key.encrypt(0)  # Initialize encrypted loss as zero\n",
        "\n",
        "        for enc_x_row, enc_y in zip(encrypted_x, encrypted_y):\n",
        "            # Forward pass through the \"dense layer\"\n",
        "            encrypted_output = dense_layer_forward(enc_x_row, weights, bias, public_key)\n",
        "\n",
        "            # Calculate encrypted loss (mean squared error approximation)\n",
        "            error = encrypted_output - enc_y\n",
        "            encrypted_loss = encrypted_multiply_constant(error, error)  # Square the error (simulated)\n",
        "\n",
        "            # Sum up the encrypted losses\n",
        "            total_encrypted_loss = encrypted_addition(total_encrypted_loss, encrypted_loss)\n",
        "\n",
        "        print(f\"Total Encrypted Loss for Epoch {epoch + 1}: {total_encrypted_loss}\")\n",
        "\n",
        "# Step 7: Main Function to Execute the Process\n",
        "def main():\n",
        "    # Step 1: Create dataset\n",
        "    x_data, y_data = create_dataset()\n",
        "\n",
        "    # Step 2: Encrypt dataset\n",
        "    encrypted_x, encrypted_y = encrypt_dataset(x_data, y_data, public_key)\n",
        "\n",
        "    # Step 3: Train on encrypted data\n",
        "    train_on_encrypted_data(encrypted_x, encrypted_y, public_key)\n",
        "\n",
        "# Execute the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "uwEhSZqBsK5p",
        "outputId": "1f251bc7-3602-4ef0-c425-0b0b0df9d6ba"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Epoch 1 ---\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "Good luck with that...",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-691dcf80ae55>\u001b[0m in \u001b[0;36m<cell line: 131>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;31m# Execute the main function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-691dcf80ae55>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;31m# Step 3: Train on encrypted data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mtrain_on_encrypted_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencrypted_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencrypted_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpublic_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;31m# Execute the main function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-691dcf80ae55>\u001b[0m in \u001b[0;36mtrain_on_encrypted_data\u001b[0;34m(encrypted_x, encrypted_y, public_key)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;31m# Calculate encrypted loss (mean squared error approximation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencrypted_output\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0menc_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mencrypted_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencrypted_multiply_constant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Square the error (simulated)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;31m# Sum up the encrypted losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-691dcf80ae55>\u001b[0m in \u001b[0;36mencrypted_multiply_constant\u001b[0;34m(enc_val, constant)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mEncryptedNumber\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mResult\u001b[0m \u001b[0mof\u001b[0m \u001b[0mmultiplication\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \"\"\"\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0menc_val\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m# Step 5: Simulate a Dense Layer Forward Pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/phe/paillier.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0;34m\"\"\"Multiply by an int, float, or EncodedNumber.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEncryptedNumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Good luck with that...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEncodedNumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: Good luck with that..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from phe import paillier\n",
        "\n",
        "# Step 1: Paillier Encryption Key Generation\n",
        "# Generate a public and private key pair for encryption\n",
        "public_key, private_key = paillier.generate_paillier_keypair()\n",
        "\n",
        "# Step 2: Dataset Creation\n",
        "# Function to create a dummy dataset with 2 features and binary labels\n",
        "def create_dataset():\n",
        "    x_data = np.random.rand(10, 2)  # 10 samples with 2 features\n",
        "    y_data = np.random.randint(0, 2, size=(10,))  # Binary labels (0 or 1)\n",
        "    return tf.data.Dataset.from_tensor_slices((x_data, y_data)).batch(2)  # Batch of size 2\n",
        "\n",
        "# Step 3: Encryption Function\n",
        "# Function to encrypt the dataset using Paillier encryption\n",
        "def encrypt_dataset(dataset, public_key):\n",
        "    encrypted_data = []\n",
        "    for x, y in dataset:\n",
        "        encrypted_x = [[public_key.encrypt(value) for value in row] for row in x.numpy()]  # Encrypt each feature\n",
        "        encrypted_y = [public_key.encrypt(int(label)) for label in y.numpy()]  # Encrypt the labels\n",
        "        encrypted_data.append((encrypted_x, encrypted_y))\n",
        "    return encrypted_data\n",
        "\n",
        "# Step 4: Decryption Function\n",
        "# Decrypt the dataset back to its original form to simulate the training process\n",
        "def decrypt_dataset(encrypted_data, private_key):\n",
        "    decrypted_data = []\n",
        "    for x, y in encrypted_data:\n",
        "        decrypted_x = [[private_key.decrypt(value) for value in row] for row in x]  # Decrypt each feature\n",
        "        decrypted_y = [private_key.decrypt(label) for label in y]  # Decrypt each label\n",
        "        decrypted_data.append((decrypted_x, decrypted_y))\n",
        "    return decrypted_data\n",
        "\n",
        "# Step 5: Model Definition\n",
        "# Define a simple neural network model for the federated learning process\n",
        "def create_model():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(2, activation='relu', input_shape=(2,)),  # Input layer with 2 features\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer with sigmoid for binary classification\n",
        "    ])\n",
        "    # Compile the model with optimizer, loss, and metrics\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Step 6: Federated Training Simulation for Scenario 2 (Decrypt Before Processing)\n",
        "def federated_training_decrypt_train_encrypt():\n",
        "    print(\"\\nScenario 2: Decrypt Before Processing\")\n",
        "    clients_data = [create_dataset() for _ in range(3)]  # Create datasets for 3 clients\n",
        "    encrypted_clients_data = [encrypt_dataset(client_data, public_key) for client_data in clients_data]  # Encrypt datasets\n",
        "\n",
        "    models = [create_model() for _ in range(3)]  # Create separate models for each client\n",
        "\n",
        "    for round_num in range(3):  # Simulate 3 rounds of training\n",
        "        print(f\"\\n--- Round {round_num + 1} ---\")\n",
        "        client_weights = []\n",
        "\n",
        "        for i, (encrypted_data, model) in enumerate(zip(encrypted_clients_data, models)):\n",
        "            # Decrypt client data before training (this step is specific to Scenario 2)\n",
        "            decrypted_data = decrypt_dataset(encrypted_data, private_key)\n",
        "\n",
        "            # Train each client model on its decrypted data\n",
        "            for x, y in decrypted_data:\n",
        "                x_train = np.array(x, dtype=np.float32)\n",
        "                y_train = np.array(y, dtype=np.float32).reshape(-1, 1)  # Reshape labels to match logits\n",
        "\n",
        "                # Train the model using the decrypted data\n",
        "                model.fit(x_train, y_train, epochs=1, verbose=0)\n",
        "\n",
        "            # Store client model weights for averaging\n",
        "            client_weights.append(model.get_weights())\n",
        "\n",
        "            # Print client model metrics after training\n",
        "            loss, acc = model.evaluate(x_train, y_train, verbose=0)\n",
        "            print(f\"Client {i+1} - Loss: {loss:.4f}, Accuracy: {acc:.4f}\")\n",
        "\n",
        "        # Server-side model aggregation: Average client weights\n",
        "        new_weights = [np.mean([client_weights[i][layer] for i in range(3)], axis=0)\n",
        "                       for layer in range(len(client_weights[0]))]\n",
        "\n",
        "        # Re-encrypt the weights before sending them back to the clients (optional in Scenario 2)\n",
        "        # In practice, this step would occur if the weights were sent back to the server for secure aggregation\n",
        "\n",
        "        # Update all client models with the aggregated weights\n",
        "        for model in models:\n",
        "            model.set_weights(new_weights)\n",
        "\n",
        "# Execute the Federated Training Process for Scenario 2\n",
        "federated_training_decrypt_train_encrypt()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjLAxsRL9cfT",
        "outputId": "8b57788c-5785-4a10-b3c5-6125144a4f93"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Scenario 2: Decrypt Before Processing\n",
            "\n",
            "--- Round 1 ---\n",
            "Client 1 - Loss: 0.7418, Accuracy: 0.5000\n",
            "Client 2 - Loss: 0.6248, Accuracy: 1.0000\n",
            "Client 3 - Loss: 0.5908, Accuracy: 1.0000\n",
            "\n",
            "--- Round 2 ---\n",
            "Client 1 - Loss: 0.6891, Accuracy: 0.5000\n",
            "Client 2 - Loss: 0.7041, Accuracy: 0.0000\n",
            "Client 3 - Loss: 0.7066, Accuracy: 0.0000\n",
            "\n",
            "--- Round 3 ---\n",
            "Client 1 - Loss: 0.6892, Accuracy: 0.5000\n",
            "Client 2 - Loss: 0.7019, Accuracy: 0.0000\n",
            "Client 3 - Loss: 0.7043, Accuracy: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjOVvavMobWB",
        "outputId": "6d991a93-8750-40a9-9b3c-fca6b25de3dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.14.1)\n",
            "Requirement already satisfied: tensorflow-federated in /usr/local/lib/python3.10/dist-packages (0.84.0)\n",
            "Requirement already satisfied: phe in /usr/local/lib/python3.10/dist-packages (1.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (22.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: attrs~=23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-federated) (23.1.0)\n",
            "Requirement already satisfied: cachetools~=5.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-federated) (5.5.0)\n",
            "Requirement already satisfied: dm-tree==0.1.8 in /usr/local/lib/python3.10/dist-packages (from tensorflow-federated) (0.1.8)\n",
            "Requirement already satisfied: dp-accounting==0.4.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-federated) (0.4.3)\n",
            "Requirement already satisfied: google-vizier==0.1.11 in /usr/local/lib/python3.10/dist-packages (from tensorflow-federated) (0.1.11)\n",
            "Requirement already satisfied: jaxlib==0.4.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow-federated) (0.4.14)\n",
            "Requirement already satisfied: jax==0.4.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow-federated) (0.4.14)\n",
            "Requirement already satisfied: portpicker~=1.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow-federated) (1.6.0)\n",
            "Requirement already satisfied: scipy~=1.9.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-federated) (1.9.3)\n",
            "Requirement already satisfied: tensorflow-model-optimization==0.7.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow-federated) (0.7.5)\n",
            "Requirement already satisfied: tensorflow-privacy==0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-federated) (0.9.0)\n",
            "Requirement already satisfied: tqdm~=4.64 in /usr/local/lib/python3.10/dist-packages (from tensorflow-federated) (4.66.5)\n",
            "Requirement already satisfied: googleapis-common-protos==1.61.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-federated) (1.61.0)\n",
            "Requirement already satisfied: mpmath~=1.2 in /usr/local/lib/python3.10/dist-packages (from dp-accounting==0.4.3->tensorflow-federated) (1.3.0)\n",
            "Requirement already satisfied: grpcio-tools>=1.35.0 in /usr/local/lib/python3.10/dist-packages (from google-vizier==0.1.11->tensorflow-federated) (1.62.3)\n",
            "Requirement already satisfied: sqlalchemy<=1.4.20,>=1.4 in /usr/local/lib/python3.10/dist-packages (from google-vizier==0.1.11->tensorflow-federated) (1.4.20)\n",
            "Requirement already satisfied: scikit-learn==1.*,>=1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-privacy==0.9.0->tensorflow-federated) (1.3.2)\n",
            "Requirement already satisfied: tensorflow-probability~=0.22.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-privacy==0.9.0->tensorflow-federated) (0.22.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.*,>=1.0->tensorflow-privacy==0.9.0->tensorflow-federated) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.*,>=1.0->tensorflow-privacy==0.9.0->tensorflow-federated) (3.5.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from portpicker~=1.6->tensorflow-federated) (5.9.5)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<=1.4.20,>=1.4->google-vizier==0.1.11->tensorflow-federated) (3.0.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability~=0.22.0->tensorflow-privacy==0.9.0->tensorflow-federated) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability~=0.22.0->tensorflow-privacy==0.9.0->tensorflow-federated) (2.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow tensorflow-federated phe\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario 1: Federated Learning with Encrypted Input & Output (Fully Encrypted Training)"
      ],
      "metadata": {
        "id": "c_m8GlPdq6DP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "from phe import paillier\n",
        "\n",
        "# Step 1: Paillier Encryption Key Generation\n",
        "public_key, private_key = paillier.generate_paillier_keypair()\n",
        "\n",
        "# Step 2: Dataset Creation\n",
        "def create_dataset():\n",
        "    x_data = np.random.rand(10, 2)  # 10 samples with 2 features\n",
        "    y_data = np.random.randint(0, 2, size=(10, 1))  # Binary labels reshaped to (10, 1)\n",
        "    return tf.data.Dataset.from_tensor_slices((x_data, y_data)).batch(2)  # Batch size 2\n",
        "\n",
        "# Step 3: Encryption Function\n",
        "def encrypt_dataset(dataset, public_key):\n",
        "    encrypted_data = []\n",
        "    for x, y in dataset:\n",
        "        encrypted_x = [[public_key.encrypt(value) for value in row] for row in x.numpy()]\n",
        "        encrypted_y = [public_key.encrypt(int(label)) for label in y.numpy().flatten()]\n",
        "        encrypted_data.append((encrypted_x, encrypted_y))\n",
        "    return encrypted_data\n",
        "\n",
        "# Step 4: Decryption Function\n",
        "def decrypt_dataset(encrypted_data, private_key):\n",
        "    decrypted_data = []\n",
        "    for x, y in encrypted_data:\n",
        "        decrypted_x = [[private_key.decrypt(value) for value in row] for row in x]\n",
        "        decrypted_y = [private_key.decrypt(label) for label in y]\n",
        "        decrypted_data.append((decrypted_x, decrypted_y))\n",
        "    return decrypted_data\n",
        "\n",
        "# Step 5: Define the Model Using Keras\n",
        "def create_model():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(2, activation='relu', input_shape=(2,)),  # Input layer with 2 features\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer with sigmoid for binary classification\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Step 6: Define a TFF model function for Federated Averaging\n",
        "def model_fn():\n",
        "    keras_model = create_model()\n",
        "    return tff.learning.models.from_keras_model(\n",
        "        keras_model,\n",
        "        input_spec=(tf.TensorSpec(shape=[None, 2], dtype=tf.float32),\n",
        "                    tf.TensorSpec(shape=[None, 1], dtype=tf.float32)),\n",
        "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "        metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
        "    )\n",
        "\n",
        "# Step 7: Federated Training Simulation for Scenario 1 (Fully Encrypted)\n",
        "def federated_training_fully_encrypted():\n",
        "    # Build Federated Averaging algorithm\n",
        "    iterative_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "        model_fn,\n",
        "        client_optimizer_fn=lambda: tf.keras.optimizers.Adam(),\n",
        "        server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0)\n",
        "    )\n",
        "\n",
        "    # Initialize the federated learning process\n",
        "    state = iterative_process.initialize()\n",
        "\n",
        "    clients_data = [create_dataset() for _ in range(3)]  # Create datasets for 3 clients\n",
        "\n",
        "    # Encrypt client data\n",
        "    encrypted_clients_data = [encrypt_dataset(client_data, public_key) for client_data in clients_data]\n",
        "\n",
        "    # Simulate multiple training rounds\n",
        "    for round_num in range(3):\n",
        "        print(f\"\\n--- Round {round_num + 1} ---\")\n",
        "\n",
        "        # Decrypt the dataset for training\n",
        "        decrypted_clients_data = [decrypt_dataset(encrypted_data, private_key) for encrypted_data in encrypted_clients_data]\n",
        "\n",
        "        # Convert decrypted data back to TFF-compatible format\n",
        "        def tff_data_format(decrypted_data):\n",
        "            x = np.array([x for x, _ in decrypted_data], dtype=np.float32)\n",
        "            y = np.array([y for _, y in decrypted_data], dtype=np.float32).reshape(-1, 1)  # Ensure (N, 1) shape for labels\n",
        "            return tf.data.Dataset.from_tensor_slices((x, y)).batch(2)\n",
        "\n",
        "        federated_data = [tff_data_format(decrypted_data) for decrypted_data in decrypted_clients_data]\n",
        "\n",
        "        # Print the shapes of batches for debugging\n",
        "        for client_idx, client_data in enumerate(federated_data):\n",
        "            print(f\"Client {client_idx+1}:\")\n",
        "            for batch in client_data:\n",
        "                print(f\"  Batch features shape: {batch[0].shape}, Batch labels shape: {batch[1].shape}\")\n",
        "\n",
        "        # Perform one round of federated training\n",
        "        state, metrics = iterative_process.next(state, federated_data)\n",
        "        print(f\"Round {round_num + 1} - Metrics: {metrics}\")\n",
        "\n",
        "# Step 8: Execute the Federated Training Process\n",
        "federated_training_fully_encrypted()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "NGwGIDtgodGk",
        "outputId": "0649d67a-6f4b-45c7-aa2e-1bfdcf5efae6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Round 1 ---\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Dimensions 5 and 10 are not compatible",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-9d91f62e04ab>\u001b[0m in \u001b[0;36m<cell line: 95>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;31m# Step 8: Execute the Federated Training Process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m \u001b[0mfederated_training_fully_encrypted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-9d91f62e04ab>\u001b[0m in \u001b[0;36mfederated_training_fully_encrypted\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mfederated_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtff_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecrypted_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdecrypted_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdecrypted_clients_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;31m# Print the shapes of batches for debugging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-9d91f62e04ab>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mfederated_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtff_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecrypted_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdecrypted_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdecrypted_clients_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;31m# Print the shapes of batches for debugging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-9d91f62e04ab>\u001b[0m in \u001b[0;36mtff_data_format\u001b[0;34m(decrypted_data)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdecrypted_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdecrypted_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure (N, 1) shape for labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mfederated_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtff_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecrypted_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdecrypted_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdecrypted_clients_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    819\u001b[0m     \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfrom_tensor_slices_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrom_tensor_slices_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m     \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/from_tensor_slices_op.py\u001b[0m in \u001b[0;36m_from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_from_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_TensorSliceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/from_tensor_slices_op.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, element, is_files, name)\u001b[0m\n\u001b[1;32m     43\u001b[0m         tensor_shape.dimension_value(self._tensors[0].get_shape()[0]))\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m       batch_dim.assert_is_compatible_with(\n\u001b[0m\u001b[1;32m     46\u001b[0m           tensor_shape.Dimension(\n\u001b[1;32m     47\u001b[0m               tensor_shape.dimension_value(t.get_shape()[0])))\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    298\u001b[0m     \"\"\"\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m       raise ValueError(\"Dimensions %s and %s are not compatible\" %\n\u001b[0m\u001b[1;32m    301\u001b[0m                        (self, other))\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Dimensions 5 and 10 are not compatible"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scenario 2: Federated Learning with Decryption Before Processing (Decrypted During Processing)"
      ],
      "metadata": {
        "id": "hU9QU5hWq4rm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "from phe import paillier\n",
        "\n",
        "# Step 1: Paillier Encryption Key Generation\n",
        "# Generate a public and private key pair for encryption\n",
        "public_key, private_key = paillier.generate_paillier_keypair()\n",
        "\n",
        "# Step 2: Dataset Creation\n",
        "# Function to create a dummy dataset with 2 features and binary labels\n",
        "def create_dataset():\n",
        "    x_data = np.random.rand(10, 2)  # 10 samples with 2 features\n",
        "    y_data = np.random.randint(0, 2, size=(10,))  # Binary labels (0 or 1)\n",
        "    return tf.data.Dataset.from_tensor_slices((x_data, y_data)).batch(2)  # Batch of size 2\n",
        "\n",
        "# Step 3: Encryption Function\n",
        "# Function to encrypt the dataset using Paillier encryption\n",
        "def encrypt_dataset(dataset, public_key):\n",
        "    encrypted_data = []\n",
        "    for x, y in dataset:\n",
        "        encrypted_x = [[public_key.encrypt(value) for value in row] for row in x.numpy()]  # Encrypt each feature\n",
        "        encrypted_y = [public_key.encrypt(int(label)) for label in y.numpy()]  # Encrypt the labels\n",
        "        encrypted_data.append((encrypted_x, encrypted_y))\n",
        "    return encrypted_data\n",
        "\n",
        "# Step 4: Decryption Function\n",
        "# Decrypt the dataset back to its original form to simulate the training process\n",
        "def decrypt_dataset(encrypted_data, private_key):\n",
        "    decrypted_data = []\n",
        "    for x, y in encrypted_data:\n",
        "        decrypted_x = [[private_key.decrypt(value) for value in row] for row in x]  # Decrypt each feature\n",
        "        decrypted_y = [private_key.decrypt(label) for label in y]  # Decrypt each label\n",
        "        decrypted_data.append((decrypted_x, decrypted_y))\n",
        "    return decrypted_data\n",
        "\n",
        "# Step 5: Define Model Using Keras\n",
        "# Create a simple sequential model for binary classification\n",
        "def create_model():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(2, activation='relu', input_shape=(2,)),  # Input layer with 2 features\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer with sigmoid for binary classification\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Step 6: Define a TFF model function for Federated Averaging\n",
        "def model_fn():\n",
        "    keras_model = create_model()\n",
        "    return tff.learning.from_keras_model(\n",
        "        keras_model,\n",
        "        input_spec=(tf.TensorSpec(shape=[None, 2], dtype=tf.float32),\n",
        "                    tf.TensorSpec(shape=[None, 1], dtype=tf.float32)),\n",
        "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "        metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
        "    )\n",
        "\n",
        "# Step 7: Federated Training Simulation for Scenario 2 (Decrypt Before Processing)\n",
        "def federated_training_decrypt_before_processing():\n",
        "    # Create the federated learning process\n",
        "    iterative_process = tff.learning.build_federated_averaging_process(model_fn)\n",
        "    state = iterative_process.initialize()\n",
        "\n",
        "    clients_data = [create_dataset() for _ in range(3)]  # Create datasets for 3 clients\n",
        "\n",
        "    # Encrypt client data\n",
        "    encrypted_clients_data = [encrypt_dataset(client_data, public_key) for client_data in clients_data]\n",
        "\n",
        "    # Simulate multiple training rounds\n",
        "    for round_num in range(3):\n",
        "        print(f\"\\n--- Round {round_num + 1} ---\")\n",
        "\n",
        "        # Decrypt the dataset before training\n",
        "        decrypted_clients_data = [decrypt_dataset(encrypted_data, private_key) for encrypted_data in encrypted_clients_data]\n",
        "\n",
        "        # Convert decrypted data back to TFF-compatible format\n",
        "        def tff_data_format(decrypted_data):\n",
        "            return tf.data.Dataset.from_tensor_slices(\n",
        "                (np.array([x for x, y in decrypted_data], dtype=np.float32),\n",
        "                 np.array([y for x, y in decrypted_data], dtype=np.float32).reshape(-1, 1))\n",
        "            ).batch(2)\n",
        "\n",
        "        federated_data = [tff_data_format(decrypted_data) for decrypted_data in decrypted_clients_data]\n",
        "\n",
        "        # Perform one round of federated training\n",
        "        state, metrics = iterative_process.next(state, federated_data)\n",
        "        print(f\"Round {round_num + 1} - Metrics: {metrics}\")\n",
        "\n",
        "# Step 8: Execute the Federated Training Process\n",
        "federated_training_decrypt_before_processing()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "XIhI0oDGodI4",
        "outputId": "06f6b316-d17e-4c72-e4db-a450d67b21db"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'tensorflow_federated.python.learning' has no attribute 'build_federated_averaging_process'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-67c3054300a4>\u001b[0m in \u001b[0;36m<cell line: 89>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;31m# Step 8: Execute the Federated Training Process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m \u001b[0mfederated_training_decrypt_before_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-67c3054300a4>\u001b[0m in \u001b[0;36mfederated_training_decrypt_before_processing\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfederated_training_decrypt_before_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# Create the federated learning process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0miterative_process\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_federated_averaging_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterative_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow_federated.python.learning' has no attribute 'build_federated_averaging_process'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8GwPyDsCodLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HAhx6X5nodOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "02iaOoPDodQw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}